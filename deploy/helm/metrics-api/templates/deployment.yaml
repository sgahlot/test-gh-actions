apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-app
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-app
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-app
    spec:
      serviceAccountName: metric-analyzer
      containers:
        - name: metrics-api
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: Always
          ports:
            - containerPort: 8000
          env:
            - name: PROMETHEUS_URL
              value: "{{ .Values.config.prometheusUrl }}"
            - name: LLM_URL
              value: "http://llama-3-2-3b-instruct-predictor.{{ .Release.Namespace }}.svc.cluster.local:8080/v1/openai/v1"
            - name: LLM_API_TOKEN
              value: "{{ .Values.llm.apiToken }}"
            - name: LLAMA_STACK_URL
              value: "http://llamastack.{{ .Release.Namespace }}.svc.cluster.local:8321/v1/openai/v1"
            - name: NAMESPACE
              value: "{{ .Release.Namespace }}"
            - name: MODEL_CONFIG
              value: '{{ .Values.modelConfig | toJson }}'
            - name: THANOS_TOKEN
              valueFrom:
                secretKeyRef:
                  name: metric-analyzer
                  key: token
          volumeMounts:
            - name: thanos-token
              mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              readOnly: true
            - name: trusted-ca
              mountPath: /etc/pki/ca-trust/extracted/pem
              readOnly: true
      volumes:
        - name: thanos-token
          secret:
            secretName: metric-analyzer
            defaultMode: 0440
        - name: trusted-ca
          configMap:
            name: trusted-ca-bundle
            items:
              - key: service-ca.crt
                path: ca-bundle.crt
